# Batch Processing Skill

## Overview
Skill ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

## Batch Processing Concepts

### What Can Be Batched
1. **Character Generation** - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
2. **Plot Outlining** - ‡∏ß‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á
3. **Chapter Writing** - ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏ó‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
4. **Quality Control** - ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô batch
5. **Export** - Export ‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô

### Batch Configurations
```yaml
batch_limits:
  character_generation:
    max_parallel: 10
    timeout_per_item: 120s

  chapter_writing:
    max_parallel: 5  # ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ä‡πâ resource ‡∏°‡∏≤‡∏Å
    timeout_per_item: 300s

  qc_processing:
    max_parallel: 20  # QC ‡πÄ‡∏ö‡∏≤‡∏Å‡∏ß‡πà‡∏≤
    timeout_per_item: 60s

  export:
    max_parallel: 10
    timeout_per_item: 180s
```

## Batch Job Structure

### Job Definition
```json
{
  "job_id": "batch-2025-01-15-001",
  "job_type": "chapter_writing",
  "created_at": "2025-01-15T00:00:00Z",
  "priority": "normal",

  "items": [
    {
      "item_id": "item-001",
      "project_id": "proj-123",
      "chapter_num": 5,
      "status": "pending"
    },
    {
      "item_id": "item-002",
      "project_id": "proj-456",
      "chapter_num": 8,
      "status": "pending"
    }
  ],

  "config": {
    "max_parallel": 5,
    "retry_on_failure": true,
    "max_retries": 2,
    "model_rotation": true
  },

  "status": "running",
  "progress": {
    "total": 20,
    "completed": 12,
    "failed": 1,
    "pending": 7
  }
}
```

## Processing Strategies

### 1. Round-Robin Model Distribution
```python
def distribute_to_models(items, models):
    """
    ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á models ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏ó‡∏µ‡∏¢‡∏°
    """
    assignments = []
    for i, item in enumerate(items):
        model = models[i % len(models)]
        assignments.append((item, model))
    return assignments

# Example
models = ["gemini", "gpt-4o", "claude-haiku"]
items = [chapter1, chapter2, chapter3, chapter4, chapter5, chapter6]
# Result:
# chapter1 ‚Üí gemini
# chapter2 ‚Üí gpt-4o
# chapter3 ‚Üí claude-haiku
# chapter4 ‚Üí gemini
# ...
```

### 2. Genre-Based Routing
```python
def route_by_genre(items):
    """
    ‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÑ‡∏õ model ‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏±‡∏î genre ‡∏ô‡∏±‡πâ‡∏ô
    """
    routing = {
        "romantic-comedy": "gemini",
        "fantasy": "gpt-4o",
        "horror": "claude-haiku",
        "mystery": "gpt-4o",
        "bl-gl": "claude-haiku"
    }

    for item in items:
        item.model = routing.get(item.genre, "gemini")
    return items
```

### 3. Load-Based Distribution
```python
def distribute_by_load(items):
    """
    ‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÑ‡∏õ model ‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    """
    model_loads = get_current_loads()

    for item in items:
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡∏ó‡∏µ‡πà load ‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        best_model = min(model_loads, key=model_loads.get)
        item.model = best_model
        model_loads[best_model] += 1

    return items
```

## Queue Management

### Priority Queue
```
Priority Levels:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. CRITICAL - Deadline < 24h        ‚îÇ
‚îÇ 2. HIGH     - Deadline < 3 days     ‚îÇ
‚îÇ 3. NORMAL   - Regular queue         ‚îÇ
‚îÇ 4. LOW      - Background tasks      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Queue Operations
```python
class BatchQueue:
    def __init__(self):
        self.queues = {
            "critical": [],
            "high": [],
            "normal": [],
            "low": []
        }

    def enqueue(self, item, priority="normal"):
        self.queues[priority].append(item)

    def dequeue(self):
        # ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å priority ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô
        for priority in ["critical", "high", "normal", "low"]:
            if self.queues[priority]:
                return self.queues[priority].pop(0)
        return None

    def get_position(self, item_id):
        position = 0
        for priority in ["critical", "high", "normal", "low"]:
            for item in self.queues[priority]:
                position += 1
                if item.id == item_id:
                    return position
        return -1
```

## Progress Tracking

### Real-time Progress
```
Batch Job: batch-2025-01-15-001
Type: Chapter Writing
Started: 00:00:00
Elapsed: 00:45:23

Progress: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 60%
           12/20 completed

Status Breakdown:
‚úÖ Completed: 12
üîÑ Running: 3
‚è≥ Pending: 4
‚ùå Failed: 1

Current Processing:
‚Ä¢ proj-123/ch7 ‚Üí gemini (30s)
‚Ä¢ proj-456/ch9 ‚Üí gpt-4o (45s)
‚Ä¢ proj-789/ch4 ‚Üí claude-haiku (20s)

Estimated Completion: 00:30:00
```

### Progress Callbacks
```python
def on_item_complete(item, result):
    """
    ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠ item ‡πÄ‡∏™‡∏£‡πá‡∏à
    """
    update_progress(item.batch_id)

    if result.success:
        log_success(item)
        trigger_next_step(item)  # ‡πÄ‡∏ä‡πà‡∏ô QC
    else:
        log_failure(item, result.error)
        if should_retry(item):
            requeue(item)
        else:
            mark_failed(item)

def on_batch_complete(batch):
    """
    ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠ batch ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à
    """
    generate_summary_report(batch)
    notify_manager(batch)
    cleanup_resources(batch)
```

## Error Handling in Batch

### Retry Strategy
```yaml
retry_config:
  max_retries: 3
  retry_delay:
    initial: 10s
    multiplier: 2
    max: 120s

  retryable_errors:
    - API_RATE_LIMIT
    - TIMEOUT
    - TEMPORARY_ERROR

  non_retryable_errors:
    - INVALID_INPUT
    - AUTH_ERROR
    - QUOTA_EXCEEDED
```

### Failure Handling
```python
def handle_batch_failure(batch, failed_items):
    """
    ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ items fail
    """
    failure_rate = len(failed_items) / batch.total_items

    if failure_rate > 0.5:
        # ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏£‡∏∂‡πà‡∏á fail - ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏±‡πâ‡∏á batch
        pause_batch(batch)
        escalate_to_manager(batch, "High failure rate")

    elif failure_rate > 0.2:
        # 20-50% fail - continue ‡πÅ‡∏ï‡πà notify
        notify_manager(batch, "Elevated failure rate")
        continue_batch(batch)

    else:
        # ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 20% - ‡∏ó‡∏≥‡∏ï‡πà‡∏≠‡∏õ‡∏Å‡∏ï‡∏¥
        continue_batch(batch)
```

## Resource Management

### Rate Limiting
```python
class RateLimiter:
    def __init__(self, model, rpm_limit, tpm_limit):
        self.model = model
        self.rpm_limit = rpm_limit
        self.tpm_limit = tpm_limit
        self.requests_this_minute = 0
        self.tokens_this_minute = 0

    def can_process(self, estimated_tokens):
        if self.requests_this_minute >= self.rpm_limit:
            return False
        if self.tokens_this_minute + estimated_tokens > self.tpm_limit:
            return False
        return True

    def record_usage(self, tokens_used):
        self.requests_this_minute += 1
        self.tokens_this_minute += tokens_used
```

### Cost Tracking
```python
def track_batch_cost(batch):
    """
    ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á batch
    """
    total_cost = 0

    for item in batch.completed_items:
        model_cost = MODEL_COSTS[item.model]
        item_cost = (
            (item.input_tokens / 1000) * model_cost["input"] +
            (item.output_tokens / 1000) * model_cost["output"]
        )
        total_cost += item_cost

    return {
        "total_cost": total_cost,
        "cost_per_item": total_cost / len(batch.completed_items),
        "budget_remaining": batch.budget - total_cost
    }
```

## Batch Reports

### Summary Report Template
```markdown
# Batch Processing Report

## Job Information
- **Job ID:** {{job_id}}
- **Type:** {{job_type}}
- **Started:** {{start_time}}
- **Completed:** {{end_time}}
- **Duration:** {{duration}}

## Results Summary
| Status | Count | Percentage |
|--------|-------|------------|
| Success | {{success_count}} | {{success_pct}}% |
| Failed | {{failed_count}} | {{failed_pct}}% |
| Skipped | {{skipped_count}} | {{skipped_pct}}% |

## Performance Metrics
- **Average Processing Time:** {{avg_time}}
- **Throughput:** {{items_per_minute}} items/min
- **Total Cost:** ${{total_cost}}
- **Cost per Item:** ${{cost_per_item}}

## Model Usage
| Model | Items | Tokens | Cost |
|-------|-------|--------|------|
{{#models}}
| {{name}} | {{items}} | {{tokens}} | ${{cost}} |
{{/models}}

## Failed Items
{{#failed_items}}
- {{item_id}}: {{error_message}}
{{/failed_items}}

## Recommendations
{{recommendations}}
```

## Best Practices

1. **Start Small** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ batch ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡πà‡∏≠‡∏ô
2. **Monitor Closely** - ‡∏î‡∏π progress ‡∏ï‡∏•‡∏≠‡∏î
3. **Set Budgets** - ‡∏Å‡∏≥‡∏´‡∏ô‡∏î cost limit
4. **Handle Failures Gracefully** - ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏´‡πâ fail ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ó‡∏≥ batch ‡∏û‡∏±‡∏á
5. **Clean Up** - ‡∏•‡∏ö temp files ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏ö
6. **Document Results** - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏ó‡∏∏‡∏Å batch
